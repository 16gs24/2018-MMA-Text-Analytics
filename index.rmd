---
title: "The Toronto Analytics Landscape"
author: "Summerhill"
date: "`r Sys.Date()`"
output:
  md_document:
    variant: markdown_github
  html_document: default
  pdf_document: default
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=5, fig.path='Figs/',
                      warning=FALSE, message=FALSE,error=FALSE,include=TRUE,echo=FALSE)

# a note on options: 
# include=TRUE means that output of the code is shown in the document (intended for graphics).
# echo=TRUE means the code is shown in the document (intended for code that might be interesting for a reader).
# message and warning are for the text for loading libraries or if a function fails
# echo=TRUE means the code is not shown in the final document
# http://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
# http://rmarkdown.rstudio.com/developer_parameterized_reports.html
```

## Examining the Analytics Job Market in Toronto
#Executive Summary
- This project was produced for the Text Analytics Workshop for the Winter 2018 Masters of Management Analytics Cohort at Queen's University
- The goal from the outset was to use text analytics techniques developed in class to examine jobs companies have posted on Indeed in Toronto
and employ techniques discussed in class including document clustering, topic modelling, and visualization.
- This document was rendered last on `r Sys.Date()`

```{r Import Libraries}
library(feather)
library(tidyverse)
library(tm)
```

```{r functions}
clean_corpus <- function(corpus,dropwords){
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, 
                   c(stopwords("en"), dropwords))
  return(corpus)
}

#cleaner but needs testing
clean_corpus <- function(Corpus,DropWordVector){
     Corpus <- Corpus %>%
          tm_map(removePunctuation) %>%
          tm_map(content_transformer(replace_abbreviation)) %>%
          tm_map(stripWhitespace) %>%
          tm_map(removeNumbers) %>%
          tm_map(content_transformer(tolower)) %>%
          tm_map(removeWords,c(stopwords("english"),DropWordVector))
     return(Corpus)
}
```

#Gathering Data
- Beautiful Soup & Selenium were used in Python to access [Indeed](https://www.indeed.ca/jobs?q=analytics&l=Toronto&start=10 "Indeed:Analytics Jobs in Toronto") and scrape unsponsored job titles, companies, and postings
- `later number` unique jobs were scraped from the search terms: `analytics`,`etc`....
- Jobs were passed from Python to R using [Feather](https://blog.rstudio.com/2016/03/29/feather/ "Feather: A Fast On-Disk Format for Data Frames for R and Python, powered by Apache Arrow")

```{r Import Data,echo=TRUE}
data <- read_feather("results_analytics_Toronto+ON.feather")
head(data,1)
```

```{r Clean Data}

```

```{r Build 1gram 2 gram Lexicons}

```

```{r Word Frequencies}

```

```{r Convert to TDM}

```

```{r Word Cloud}

```

```{r Network Analysis}
print("Hello World")
```






